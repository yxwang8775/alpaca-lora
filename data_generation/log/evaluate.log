nohup: ignoring input
/home/wangyaoxiang/anaconda3/envs/bigbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: /home/wangyaoxiang/anaconda3/envs/bigbench did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...
  warn(msg)
/home/wangyaoxiang/anaconda3/envs/bigbench/lib/python3.8/site-packages/bitsandbytes/cuda_setup/main.py:145: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib')}
  warn(msg)
<module 'bigbench.api.task' from '/home/wangyaoxiang/codes/BIG-bench/bigbench/api/task.py'>

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please run

python -m bitsandbytes

 and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
bin /home/wangyaoxiang/anaconda3/envs/bigbench/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so
CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so
CUDA SETUP: Highest compute capability among GPUs detected: 8.0
CUDA SETUP: Detected CUDA version 117
CUDA SETUP: Loading binary /home/wangyaoxiang/anaconda3/envs/bigbench/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...
0
modelname=decapoda-research/llama-7b-hf
device=cuda
Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/33 [00:00<00:09,  3.48it/s]Loading checkpoint shards:   6%|▌         | 2/33 [00:00<00:08,  3.52it/s]Loading checkpoint shards:   9%|▉         | 3/33 [00:00<00:08,  3.51it/s]Loading checkpoint shards:  12%|█▏        | 4/33 [00:01<00:08,  3.55it/s]Loading checkpoint shards:  15%|█▌        | 5/33 [00:01<00:07,  3.55it/s]Loading checkpoint shards:  18%|█▊        | 6/33 [00:01<00:07,  3.57it/s]Loading checkpoint shards:  21%|██        | 7/33 [00:01<00:07,  3.47it/s]Loading checkpoint shards:  24%|██▍       | 8/33 [00:02<00:07,  3.43it/s]Loading checkpoint shards:  27%|██▋       | 9/33 [00:02<00:07,  3.36it/s]Loading checkpoint shards:  30%|███       | 10/33 [00:02<00:06,  3.31it/s]Loading checkpoint shards:  33%|███▎      | 11/33 [00:03<00:06,  3.28it/s]Loading checkpoint shards:  36%|███▋      | 12/33 [00:03<00:06,  3.28it/s]Loading checkpoint shards:  39%|███▉      | 13/33 [00:03<00:06,  3.27it/s]Loading checkpoint shards:  42%|████▏     | 14/33 [00:04<00:05,  3.26it/s]Loading checkpoint shards:  45%|████▌     | 15/33 [00:04<00:05,  3.29it/s]Loading checkpoint shards:  48%|████▊     | 16/33 [00:04<00:05,  3.29it/s]Loading checkpoint shards:  52%|█████▏    | 17/33 [00:05<00:04,  3.30it/s]Loading checkpoint shards:  55%|█████▍    | 18/33 [00:05<00:04,  3.31it/s]Loading checkpoint shards:  58%|█████▊    | 19/33 [00:05<00:04,  3.35it/s]Loading checkpoint shards:  61%|██████    | 20/33 [00:05<00:03,  3.37it/s]Loading checkpoint shards:  64%|██████▎   | 21/33 [00:06<00:03,  3.35it/s]Loading checkpoint shards:  67%|██████▋   | 22/33 [00:06<00:03,  3.25it/s]Loading checkpoint shards:  70%|██████▉   | 23/33 [00:06<00:02,  3.33it/s]Loading checkpoint shards:  73%|███████▎  | 24/33 [00:07<00:02,  3.42it/s]Loading checkpoint shards:  76%|███████▌  | 25/33 [00:07<00:02,  3.49it/s]Loading checkpoint shards:  79%|███████▉  | 26/33 [00:07<00:02,  3.48it/s]Loading checkpoint shards:  82%|████████▏ | 27/33 [00:07<00:01,  3.47it/s]Loading checkpoint shards:  85%|████████▍ | 28/33 [00:08<00:01,  3.47it/s]Loading checkpoint shards:  88%|████████▊ | 29/33 [00:08<00:01,  3.46it/s]Loading checkpoint shards:  91%|█████████ | 30/33 [00:08<00:00,  3.45it/s]Loading checkpoint shards:  94%|█████████▍| 31/33 [00:09<00:00,  3.42it/s]Loading checkpoint shards:  97%|█████████▋| 32/33 [00:09<00:00,  3.41it/s]Loading checkpoint shards: 100%|██████████| 33/33 [00:09<00:00,  3.26it/s]Loading checkpoint shards: 100%|██████████| 33/33 [00:09<00:00,  3.37it/s]
Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.
2023-05-11 15:50:51.093680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
modeldevice=cuda:0
lora=None
4
5
6
tokenizer=LlamaTokenizer(name_or_path='/nvme/wangyaoxiang/model/llama-7b-hf/snapshots/5f98eefcc80e437ef68d457ad7bf167c2c6a1348', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken("", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken("", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken("", rstrip=False, lstrip=False, single_word=False, normalized=True)}, clean_up_tokenization_spaces=False)
device=cuda:0
1
2
target=0
target=1
target=2
target=3
target=4
target=5
target=6
target=7
target=8
target=9
target=10
target=11
target=12
target=13
target=14
target=15
target=16
target=17
target=18
target=19
target=20
target=21
target=22
target=23
target=24
target=25
target=26
target=27
target=28
target=29
target=30
target=31
target=32
target=33
target=34
target=35
target=36
target=37
target=38
target=39
target=40
target=41
target=42
target=43
target=44
target=45
target=46
target=47
target=48
target=49
target=50
target=51
target=52
target=53
target=54
target=55
target=56
target=57
target=58
target=59
target=60
target=61
target=62
target=63
target=64
target=65
target=66
target=67
target=68
target=69
target=70
target=71
target=72
target=73
target=74
target=75
target=76
target=77
target=78
target=79
target=80
target=81
target=82
target=83
target=84
target=85
target=86
target=87
target=88
target=89
target=90
target=91
target=92
target=93
target=94
target=95
target=96
target=97
target=98
target=99
target=100
ScoreData(score_dict={'0': 41, '1': 40, '2': 39, '3': 38, '4': 37, '5': 36, '6': 35, '7': 34, '8': 33, '9': 32, '10': 31, '11': 30, '12': 29, '13': 28, '14': 27, '15': 26, '16': 25, '17': 24, '18': 23, '19': 22, '20': 21, '21': 20, '22': 19, '23': 18, '24': 17, '25': 16, '26': 15, '27': 14, '28': 13, '29': 12, '30': 11, '31': 10, '32': 9, '33': 8, '34': 7, '35': 6, '36': 5, '37': 4, '38': 3, '39': 2, '40': 1, '41': 0, '42': 0, '43': 0, '44': 0, '45': 0, '46': 0, '47': 0, '48': 0, '49': 0, '50': 0, '51': 1, '52': 2, '53': 3, '54': 4, '55': 5, '56': 6, '57': 7, '58': 8, '59': 9, '60': 10, '61': 11, '62': 12, '63': 13, '64': 14, '65': 15, '66': 16, '67': 17, '68': 18, '69': 19, '70': 20, '71': 21, '72': 22, '73': 23, '74': 24, '75': 25, '76': 26, '77': 27, '78': 28, '79': 29, '80': 30, '81': 31, '82': 32, '83': 33, '84': 34, '85': 35, '86': 36, '87': 37, '88': 38, '89': 39, '90': 40, '91': 41, '92': 42, '93': 43, '94': 44, '95': 45, '96': 46, '97': 47, '98': 48, '99': 49, '100': 50, 'full': -21.14851485148515}, preferred_score='full', number_of_shots=0, low_score=-100.0, high_score=-0.0, subtask_description='high_low_game')
